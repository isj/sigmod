__notes__

duplicate hits

Q10 0 0 3 AND REGEX WILL
Q11 3 3 4 AND REGEX WILL TEAT


Doc   BAND   -> AND  edit_match_3, edit_match_2, edit_match_1   
    -> hit (Q11)
        ->  decrement Doc/Q11
Doc   AND    -> AND  exact match, edit_match_3, edit_match_2, edit_match_1  
    -> hit (Q10, Q11) 
        -> decrement Doc/Q10 (only if we have not decremented it for this word already)
        -> decrement Doc/Q11 (only if we have not decremented it for this word already)
        so per document,we need to keep an index per query word, not just index of word counts.
        this is because 
            some matches cover more than one type
            different doc words can match one query word
            for a given doc, a terminal node must decrement a query ONLY ONCE
            
            10  3
            11  2
           
           per DOC, per NODE [list of queries]
           we'd keep a list of node references, with queries
           OR... we'd keep a list of queries.wordnumber
         or...
           per NODE, per DOC [list of queries]
           each node would keep a list of (docs, list of queries)
           but when the doc is gone we would want to erase the doc's list
           for a word, couldnt we just keep 
           
           max query words is 5
           so we'd have doc_number*10+query_word_number
           eg 105 241
           or doc_number<<3 + query_word_number
           so each doc_list would be 101,102,103 111,112,113,114,121,122,123,124
           then we decrement (remove) exact number
            101,102,103 111,112,113,114,121,122,123,124
             101,102,103 111,112,113,114,121,122,124
              101,102,103 111,112,113,114,121,122,124
              
              but how would we know which queries are completely satisfied?
              
              instead, we can keep a SCORE for each query, which is an elaboration of WORD COUNT
              
              instead of 
               10->3
               11->4
               
               we could have
               10->00111  [=7]  (word count 3)
               11->01111  [=15] (word count 4)
               
               
               and fully...
               ->00001 [= 1] (word count 1)
               ->00011 [= 3] (word count 2)
               ->00111 [= 7] (word count 3)
               ->01111 [=15] (word count 4)
               ->11111 [=31] (word count 5)
               
               Then to decrement, we decrement taking account of which word we have found
               To remove word 1 decrement 2^0=1
               decrement (number, 00001)
               d ( 1,00001) =  0 = 00000;
               d ( 3,00001) =  2 = 00010;
               d ( 7,00001) =  6 = 00110;
               d (15,00001) = 14 = 01110; 
               d (31,00001) = 30 = 11110;
               To remove word 2 decrement 2^1=2
               decrement (number, 00010)
               d ( 1,00010) =  1 = 00001; //no change, there is no word 2
               d ( 3,00010) =  1 = 00001;
               d ( 7,00010) =  5 = 00101;
               d (15,00010) = 13 = 01101;
               d (31,00010) = 29 = 11101;
               To remove word 3 decrement 2^2=4
               decrement (number, 00100)
               d ( 1,00100) =  1 = 00001; //no change, there is no word 3
               d ( 3,00100) =  3 = 00011; //no change, there is no word 3
               d ( 7,00100) =  3 = 00011;
               d (15,00100) = 13 = 01011;
               d (31,00100) = 29 = 11011;   
               To remove word 4 decrement 2^3=8
               decrement (number, 01000)
               d ( 1,01000) =  1 = 00001; //no change, there is no word 4
               d ( 3,01000) =  3 = 00011; //no change, there is no word 4
               d ( 7,01000) =  7 = 00111; //no change, there is no word 4
               d (15,01000) =  7 = 00111;
               d (31,01000) = 23 = 10111;
               To remove word 5 decrement 2^4=16
               decrement (number, 01000)
               d ( 1,10000) =  1 = 00001; //no change, there is no word 5
               d ( 3,10000) =  3 = 00011; //no change, there is no word 5
               d ( 7,10000) =  7 = 00111; //no change, there is no word 5
               d (15,10000) = 15 = 01111; //no change, there is no word 5
               d (31,10000) = 15 = 01111;
               decrement (number, 00100)
               to remove word 4
               decrement (number, 01000)
               to remove word 5
               decrement (number, 10000)
               


              
              10->11111  - 31 - 5 words
              11->11011  -
              11->10011
              set bits to 0
              when all bits are 0 we have a hit
              so we decrement a bit_place
              so we need to know which bit_place to decrement
              so we store 101(say)
              bit number is 
              
            
              
              1 1 0
              1 0 1
              0 1 0
              0 0 0
              
              
              1 1 1
              1 0 1
              0 1 1
              0 0 0  OR
              
              1 1 0
              1 0 0
              0 1 0
              0 0 1 XOR
              
              1 1 1 
              1 0 0
              0 1 0
              0 0 0 AND
              
              1 1 0
              1 0 0
              0 1 0
              0 0 1 NOT
              
              1 1 0
              1 0 1
              0 1 1
              0 0 1 NAND
              
              number:        11110    11010
              bit to delete: 00100    00100

              AND            00100 or 00000

              SUBTRACt       11110 -  11010 -
                             00100    00000
                             
                             11010    11010
                             
                             
int deleteBit (number, bit) {

        num = number & bit;
        return number - num;
}


int query_ref (int queryID, int wordNumber) {
       int ref = queryID << 3;
       int ref += wordNumber;
       return intRef;

}

int queryIDfromRef (int query_ref) {

     return query_ref >> 3;
}

int queryWordFromRef (int query_ref) {

    return query_ref - queryIDFromRef();

}

decrmeneet (QueryID, wordNumber) {

       if wordNumber is 1, remove the first bit  // subtract 1
       if wordNumber is 2, remove the second bit //subtract 2
       if wordNumber is 3, remove the third bit //subtract 4
       QueryIDVal = QUeryIDVal - wordNumberBit;

}



Eliminating duplicates

EITHER
1. As we process the document, we can accumulate a word set. If a word is in the set, don't tumble it again
The set will be size <= document
We will only tumble unique document words
is there a way to index these words without copying?
should we build a trie of the document?
OR
2. As we get hits, we cam accumultate a matched word set. If a hit is in the set, don't  score again
The set will be size <= hits
We will tumble every document word

Exact match

looping MatchDocument x 1000 on an exact-match-only set of queries (4 x queries, 60 x documents)



Your program has successfully passed all tests.
docs: 960 queries: 993 end_queries: 1013
exact_match: 993 hamming_distance: 0 edit_distance: 0
Time=21111[21s:111ms]
Program ended with exit code: 0

Your program has successfully passed all tests.
docs: 960 queries: 406 end_queries: 1013
exact_match: 0 hamming_distance: 406 edit_distance: 0
Time=8367[8s:367ms]
Program ended with exit code: 0

Your program has successfully passed all tests.
docs: 960 queries: 521 end_queries: 1013
exact_match: 0 hamming_distance: 0 edit_distance: 521
Time=212353[3m:32s:353ms]
Program ended with exit code: 0

selvans code
exact_match: 993 hamming_distance: 406 edit_distance: 521
Time=880973[14m:40s:973ms]

default code
exact_match: 993 hamming_distance: 406 edit_distance: 521
Time=326319[5m:26s:319ms]
Program ended with exit code: 0



if(strcmp(query_word, doc_word)==0)  matching_word=true;

Your program has successfully passed all tests.
docs: 960 queries: 993 end_queries: 1013
exact_match: 993 hamming_distance: 0 edit_distance: 0
Time=20787[20s:787ms]
Program ended with exit code: 0

build a trie tree

Class Trie Tree {
     
     Trie_Node root;  //make sure to initalise ROOT with word_length 0.
     
     function insert_word (query_str, query_id, match_type, match_dist) {
     
     
     
     
     }


     


}

CLASS Trie Node
    char letter;
    Tie Node parent;
    int depth;
     char* [26] child_alphabet;   //initialise with 26 elements val oo
     vetor <int>word_lengths;
      bool terminator
        vector <int> q_exact_match   //query_ids of exact_match queries containting this word
        vector <int> q_hamming_1    //query_ids of hamming_match_1 queries containing this word
        vector <int> q_hamming_2   //query_ids of hamming_match_2 queries containing this word
        vector <int> q_edit_1   //query_ids of edit_distance_1 queries containing this word
        vector <int> q_edit_2   //query_ids of edit_distance_2 queries containing this word
    }
       vector <int> matching_docs  //do we need this?
       
       - void check_match_valid (query_id, match_type) {
          look up query_Id in list of eliminated queries
          if it is there, delete it from match_type
          
         // this way we don't need to delete eliminated entries.
         // OPTIMISATION=>may need to reconsider for deleting eliminated entries.

       }
       


       -void match_found (doc_id, query_id) {
            decrement the doc_id query_index
       }
       
       -void add_char (query_char, query_id, match_type, match_dist) {
       //adding the next character from a new query word;
       
            if (query_char == \0) {  //we've reached the end for this query word
                //reached word termination
                switch (match_type){
                   case exact_match:
                    push_back(q_exact_match, query_id);
                   break;
                   case hamming_match:
                     if (match_dist == 1) push_back (q_hamming_1, query_id)
                     else push_back (q_hammning_2, query_id)
                   break;
                   case edit_distance:
                     if (match_dist == 1) push_back (q_edit_1, query_id)
                     else push_back (q_edit_2, query_id)    
                   break;
                }
            
            } else {  // not yet terminating

                if (child_alphabet[char]==oo) {
                    new Trie Node [query_char]
                }
                TrieNode* node = child_alphabet[char];

                node::add_char (query_char+1, query_id, match_type, match_dist)
            }
       }
       


       - void log_node_depths {
       //when we have reached the final insert of a new query_word, only then do we know our word length.
       //Npw climb back up the tree to register word_length with every parent node.
       //we use this info at every node to work out whether to explore the tree further
       //(eg if doc-word length is 8 but following this node only yields query words max 6 length, don't bother)
           parent add_word_length[self.depth]

       }

       - int  depth {
       if (!_depth) {
          _depth = parent.depth+1;
        }
        return _depth;
       }
}


#!/usr/bin/python
#By Steve Hanov, 2011. Released to the public domain
import time
import sys

DICTIONARY = "/usr/share/dict/words";
TARGET = sys.argv[1]
MAX_COST = int(sys.argv[2])

# Keep some interesting statistics
NodeCount = 0
WordCount = 0

# The Trie data structure keeps a set of words, organized with one node for
# each letter. Each node has a branch for each letter that may follow it in the
# set of words.
class TrieNode:
    def __init__(self):
        self.word = None
        self.children = {}

        global NodeCount
        NodeCount += 1

    def insert( self, word ):
        node = self
        for letter in word:
            if letter not in node.children: 
                node.children[letter] = TrieNode()

            node = node.children[letter]

        node.word = word

# read dictionary file into a trie
trie = TrieNode()
for word in open(DICTIONARY, "rt").read().split():
    WordCount += 1
    trie.insert( word )

print "Read %d words into %d nodes" % (WordCount, NodeCount)

# The search function returns a list of all words that are less than the given
# maximum distance from the target word

def search( word, maxCost ):

    # build first row
    currentRow = range( len(word) + 1 )

    results = []

    # recursively search each branch of the trie
    for letter in trie.children:
        searchRecursive( trie.children[letter], letter, word, currentRow, 
            results, maxCost )

    return results

# This recursive helper is used by the search function above. It assumes that
# the previousRow has been filled in already.

def searchRecursive( node, letter, word, previousRow, results, maxCost ):

    columns = len( word ) + 1
    currentRow = [ previousRow[0] + 1 ]

    # Build one row for the letter, with a column for each letter in the target
    # word, plus one for the empty string at column 0
    for column in xrange( 1, columns ):

        insertCost = currentRow[column - 1] + 1
        deleteCost = previousRow[column] + 1

        if word[column - 1] != letter:
            replaceCost = previousRow[ column - 1 ] + 1
        else:                
            replaceCost = previousRow[ column - 1 ]

        currentRow.append( min( insertCost, deleteCost, replaceCost ) )

    # if the last entry in the row indicates the optimal cost is less than the
    # maximum cost, and there is a word in this trie node, then add it.
    if currentRow[-1] <= maxCost and node.word != None:
        results.append( (node.word, currentRow[-1] ) )

    # if any entries in the row are less than the maximum cost, then 
    # recursively search each branch of the trie
    if min( currentRow ) <= maxCost:
        for letter in node.children:
            searchRecursive( node.children[letter], letter, word, currentRow, 
                results, maxCost )

start = time.time()
results = search( TARGET, MAX_COST )
end = time.time()

for result in results: print result        
1
print "Search took %g s" % (end - start)


unordered set - duplicate filters 1233 1206 1297 1239 1040 1193
unordered_set + duplicates filter 1396 1393 1486 1387 1493 1317


ordered set + duplicate filters 2684 2669 2492 2816 2349 2568


r2RecursiveSearch
        one wrapped-up search for edit, hamming and exact
        we probe each child node
        decide on appropriate search_types
        process those search_types
  
typedef enum searchType {
               kSearchTypeExact
               kSearchTypeHamming << 1
               kSearchType
}
        
r2RecursiveSearch (
        
        

        
        




